{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step by step guide to the codes used in the sentiment analysis**\n",
    "**of the North Carolina Medicaid Reform Public Comments in 2016**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Load helper library files needed for the code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load helper files\n",
    "import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "import pandas as pd\n",
    "import string\n",
    "import json\n",
    "import pprint\n",
    "import hashlib\n",
    "from colorama import Fore, Back, Style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Set the variables for the subscription key and region for the Azure Cognitive Services**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the keys and region where the cognitive services are accessed\n",
    "\"\"\"\n",
    "    Replace: \n",
    "    1. Dummy key with your own Azure key from the Azure Cognitive Services resource\n",
    "    2. Dummy endpoint endpoint from the Azure Cognitive Services resource without the https://\n",
    "       For example, if the endpoint on the resource is https://eastus.azure.com, \n",
    "       replace the 'Dummy endpoint' with 'eastus.azure.com'\n",
    "\"\"\"\n",
    "subscription_key = \"150f10fe96b34990a527b9de60aae711\" # \n",
    "cognitive_services_region = \"westus2.api.cognitive.microsoft.com\" \n",
    "\n",
    "# Set the request headers and parameters\n",
    "headers = {\n",
    "    # Request headers\n",
    "    'Content-Type': 'application/json',\n",
    "    'Ocp-Apim-Subscription-Key':subscription_key\n",
    "}\n",
    "params = urllib.parse.urlencode({\n",
    "  # Request parameters\n",
    "  'showStats': 'false',\n",
    "  'model-version': 'V1',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Load the downloaded comment file into a data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>nwords</th>\n",
       "      <th>hashed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Please make sure that federally qualified heal...</td>\n",
       "      <td>53</td>\n",
       "      <td>4603853928484254947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>The Medicaid reform proposal ignores some high...</td>\n",
       "      <td>415</td>\n",
       "      <td>-3005735205235233030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>As an employee of a Western North Carolina Com...</td>\n",
       "      <td>206</td>\n",
       "      <td>3113130487395667677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I strongly urge you to include Medicaid Expasi...</td>\n",
       "      <td>79</td>\n",
       "      <td>1737853792026592288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The Department of Social Services needs to be ...</td>\n",
       "      <td>30</td>\n",
       "      <td>-5225945899384959805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  nwords  \\\n",
       "0  Please make sure that federally qualified heal...      53   \n",
       "1  The Medicaid reform proposal ignores some high...     415   \n",
       "2  As an employee of a Western North Carolina Com...     206   \n",
       "3  I strongly urge you to include Medicaid Expasi...      79   \n",
       "4  The Department of Social Services needs to be ...      30   \n",
       "\n",
       "                hashed  \n",
       "0  4603853928484254947  \n",
       "1 -3005735205235233030  \n",
       "2  3113130487395667677  \n",
       "3  1737853792026592288  \n",
       "4 -5225945899384959805  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the comment file into a data frame\n",
    "\"\"\"\n",
    "    The file used in this demonstrations 'NC Medicaid Comments 062016a.csv' is downloaded \n",
    "    directly from the NC MEDICAID site listed below\n",
    "    https://public.medicaid.gov/connect.ti/public.comments/questionnaireResults?qid=1886531 \n",
    "    Public Comments on this site are from June to July 2016\n",
    "\"\"\"\n",
    "commentData = pd.read_csv(\"NC Medicaid Comments 062016a.csv\", header=0, names=[\"comment\"])\n",
    "\n",
    "commentData['nwords'] = commentData.comment.apply(lambda x: len(x.split()))\n",
    "commentData['hashed'] = commentData.comment.apply(lambda x: hash(\"\".join(x.split())))\n",
    "\n",
    "# Remove duplicated record but keep the first occurence of the record\n",
    "commentData.drop_duplicates(keep='first',inplace=True)\n",
    "# Reindex the data frame to prevent gaps in the indexes\n",
    "commentData.reset_index(drop=True, inplace=True)\n",
    "commentData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Help functions**. <br>\n",
    " -  _process_comment_  takes a dataframe with the comments in text and call the other functions to process frame\n",
    " -  _comment_sentiment_ takes a comment and returns the sentiment by calling the Text Analytics API\n",
    " -  _comment_summary_  takes the result from _comment_sentiment_ and summarizes the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_comment (comment_df): \n",
    "    \"\"\"\n",
    "    Take the data frame, get the sentiments and save result to a CSV file\n",
    "\n",
    "    Args:\n",
    "        comment_df -- Data frame containing the text to analyze.\n",
    "    Returns:\n",
    "         A data frame consisting of the relevant columns\n",
    "         'id','sentiment', 'positive','negative','neutral'. \n",
    "    \"\"\"\n",
    "    df2 = comment_df\n",
    "    # Drop any existing index and use a new one\n",
    "    df2.reset_index(drop=True, inplace=True) \n",
    "    print(u\"Processing records in data frame....\")\n",
    "    for i, row in df2.iterrows():\n",
    "        #print(u\"Processing Record... #{}\".format(i+1))\n",
    "        text_data = df2.loc[i,\"comment\"].encode(\"utf-8\").decode(\"ascii\", \"ignore\")\n",
    "        sentimentResult = comment_sentiment (text_data, i+1)\n",
    "        sentimentSummary = comment_summary(sentimentResult)\n",
    "        # Add result to data frame\n",
    "        df2.loc[i, \"id\"] = i+1\n",
    "        df2.loc[i, \"sentiment\"] = sentimentSummary['Sentiment']\n",
    "        df2.loc[i, \"positive\"] = sentimentSummary['Positive']\n",
    "        df2.loc[i, \"negative\"] = sentimentSummary['Negative']\n",
    "        df2.loc[i, \"neutral\"] = sentimentSummary['Neutral']\n",
    "        dfx = df2[['id','sentiment', 'positive','negative','neutral']]\n",
    "    print(u\"Processing completed....\")\n",
    "    # Ensure that numbers are represented as integers and not float\n",
    "    convert_dict = {'id': int, \n",
    "                'positive': int,\n",
    "                'negative': int,\n",
    "                'neutral': int,\n",
    "                'sentiment': str\n",
    "               } \n",
    "  \n",
    "    dfx = dfx.astype(convert_dict)\n",
    "    return  dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_sentiment(comment=\"Welcome to sentiment analysis with Azure Cognitive Services Text Analytics API.\", cid=1):\n",
    "    \"\"\"\n",
    "    Take a single comment in string and analyze the sentiment\n",
    "\n",
    "    Args:\n",
    "        comment --  The text content to analyze. \n",
    "        Default comment:\n",
    "                \"Welcome to sentiment analysis with Azure Cognitive Services Text Analytics API\"\n",
    "        cid -- The numeric id of the comment analyzed. \n",
    "        Default value is 1\n",
    "    \"\"\"\n",
    "    language = \"en\"\n",
    "    try:\n",
    "        document = {\"id\": cid, \"language\": language, \"text\": comment }\n",
    "        body = {\"documents\": [document]}\n",
    "        #print(document)\n",
    "        #print(str(document))\n",
    "        conn = http.client.HTTPSConnection(cognitive_services_region)\n",
    "        conn.request(\"POST\", \"/text/analytics/v3.0-preview.1/sentiment\", str(body), headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read()\n",
    "        # Extract key phrases\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_summary(commentData):\n",
    "    \"\"\"\n",
    "        Take a single response data from comment_sentiment function and summarizes the result\n",
    "\n",
    "        Args:\n",
    "            commentData --  The text response data to summarize. \n",
    "    \"\"\"\n",
    "    responseJson = json.loads(commentData)\n",
    "    summary = {\"Id\": 0, \"Sentiment\": \"\", \"Positive\":0,\"Neutral\":0,\"Negative\":0}\n",
    "    for document in responseJson['documents']:\n",
    "      summary[\"Sentiment\"] = document['sentiment'].capitalize()\n",
    "      summary[\"Id\"] = document['id']\n",
    "      for each in document['sentences']:\n",
    "         sentimentscore = each['sentiment']\n",
    "         if sentimentscore == 'positive': \n",
    "            summary[\"Positive\"] +=1\n",
    "         elif sentimentscore  == 'negative':\n",
    "            summary[\"Negative\"] +=1\n",
    "         else:\n",
    "            summary[\"Neutral\"] +=1\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing records in data frame....\n",
      "Processing completed....\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id sentiment  positive  negative  neutral\n",
       "0   1     Mixed         1         1        0\n",
       "1   2     Mixed         6         6        9\n",
       "2   3  Negative         0         4        1\n",
       "3   4  Negative         0         3        2\n",
       "4   5  Negative         0         1        1\n",
       "5   6     Mixed         3         4        0\n",
       "6   7   Neutral         0         0        2\n",
       "7   8     Mixed         3         1        0\n",
       "8   9     Mixed         1         1        1\n",
       "9  10     Mixed         2         1        2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = process_comment(commentData)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1398\n"
     ]
    }
   ],
   "source": [
    "#Save result to CSV to be used in PowerBI\n",
    "df.to_csv('csv_example.csv')\n",
    "print(len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
